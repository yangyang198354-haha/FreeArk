import logging
from datetime import datetime, date, timedelta
from django.db import transaction, connection, close_old_connections
from django.utils import timezone
from django.db.models import Max, Subquery, OuterRef, F
from api.models import PLCData, UsageQuantityDaily

# æ³¨æ„ï¼šDjangoçš„æ—¶åŒºå¤„ç† - è®¾ç½®TIME_ZONE='Asia/Shanghai'ä¸”USE_TZ=Trueæ—¶ï¼Œ
# æ•°æ®åº“ä¸­å­˜å‚¨UTCæ—¶é—´ï¼Œä½†åœ¨Pythonä»£ç ä¸­æ“ä½œæ—¶ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºæœ¬åœ°æ—¶åŒº

logger = logging.getLogger(__name__)

class DailyUsageCalculator:
    """
    æ¯æ—¥ç”¨é‡è®¡ç®—å·¥å…·ç±»ï¼ŒåŒ…å«å…±äº«çš„è®¡ç®—é€»è¾‘
    ä¼˜åŒ–ç‰ˆæœ¬ï¼šé’ˆå¯¹å¤§æ•°æ®é‡åœºæ™¯ä¼˜åŒ–äº†æ•°æ®åº“æŸ¥è¯¢å’Œæ“ä½œ
    """
    
    # æ‰¹é‡å¤„ç†çš„æ‰¹æ¬¡å¤§å°
    BATCH_SIZE = 100
    
    # ç¼“å­˜å·²è§£æçš„specific_partç»“æœï¼Œé¿å…é‡å¤è§£æ
    _specific_part_cache = {}

    @classmethod
    def calculate_daily_usage(cls, target_date, log_func=None, batch_size=None):
        """
        è®¡ç®—æŒ‡å®šæ—¥æœŸçš„æ¯æ—¥ç”¨é‡æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
        
        Args:
            target_date: è¦è®¡ç®—çš„ç›®æ ‡æ—¥æœŸ
            log_func: æ—¥å¿—è®°å½•å‡½æ•°ï¼Œé»˜è®¤ä¸ºlogger.info
            batch_size: æ‰¹é‡å¤„ç†çš„æ‰¹æ¬¡å¤§å°ï¼Œé»˜è®¤ä½¿ç”¨ç±»å¸¸é‡BATCH_SIZE
            
        Returns:
            dict: åŒ…å«å¤„ç†ç»“æœç»Ÿè®¡çš„å­—å…¸
        """
        # å¦‚æœæ²¡æœ‰æä¾›æ—¥å¿—å‡½æ•°ï¼Œä½¿ç”¨logger.info
        if log_func is None:
            log_func = logger.info
            
        # ä½¿ç”¨æä¾›çš„æ‰¹æ¬¡å¤§å°æˆ–é»˜è®¤å€¼
        if batch_size is None:
            batch_size = cls.BATCH_SIZE
        
        try:
            # å…³é—­æ—§çš„æ•°æ®åº“è¿æ¥ï¼Œç¡®ä¿ä½¿ç”¨æ–°çš„æœ‰æ•ˆè¿æ¥
            close_old_connections()
            
            # ç¡®ä¿target_dateå¸¦æ—¶åŒº
            if isinstance(target_date, date) and not isinstance(target_date, datetime):
                # å¦‚æœæ˜¯dateå¯¹è±¡ï¼Œè½¬æ¢ä¸ºå¸¦æ—¶åŒºçš„datetimeå¯¹è±¡ï¼ˆå½“æ—¥çš„00:00:00ï¼‰
                naive_datetime = datetime.combine(target_date, datetime.min.time())
                target_date = timezone.make_aware(naive_datetime)
            elif isinstance(target_date, datetime) and target_date.tzinfo is None:
                # å¦‚æœæ˜¯ä¸å¸¦æ—¶åŒºçš„datetimeå¯¹è±¡ï¼Œæ·»åŠ æ—¶åŒº
                target_date = timezone.make_aware(target_date)
            
            log_func(f"è®¡ç®—æ—¥æœŸ: {target_date.date() if isinstance(target_date, datetime) else target_date}")
            
            # è·å–æ¬¡æ—¥æ—¥æœŸ
            if isinstance(target_date, datetime):
                next_day = (target_date + timedelta(days=1)).date()
            else:
                next_day = target_date + timedelta(days=1)
            
            processed_count = 0
            created_count = 0
            updated_count = 0
            next_day_count = 0
            
            # ä½¿ç”¨target_dateçš„æ—¥æœŸéƒ¨åˆ†
            target_date_value = target_date.date() if isinstance(target_date, datetime) else target_date
            
            # ç¼“å­˜ä»¥æé«˜æ€§èƒ½
            cls._specific_part_cache.clear()
            
            # ä¼˜åŒ–ï¼šä½¿ç”¨å­æŸ¥è¯¢å’ŒOuterRefè·å–æ¯ä¸ª(specific_part, energy_mode)ç»„åˆçš„æœ€æ–°è®°å½•
            # è¿™æ ·å¯ä»¥ç¡®ä¿åªè·å–æ¯ä¸ªç»„åˆçš„æœ€æ–°è®°å½•ï¼Œé¿å…é‡å¤æ•°æ®
            log_func("è·å–æ¯ä¸ªç‰¹å®šéƒ¨åˆ†å’Œèƒ½æºæ¨¡å¼ç»„åˆçš„æœ€æ–°è®°å½•")
            
            # ç›´æ¥æŒ‰ç›®æ ‡æ—¥æœŸè¿‡æ»¤è·å–æ‰€æœ‰è®°å½•ï¼Œå› ä¸ºæ¯ä¸ª (specific_part, energy_mode) åœ¨ç›®æ ‡æ—¥æœŸä¸‹åªæœ‰ä¸€æ¡è®°å½•
            latest_records_qs = PLCData.objects.filter(
                usage_date=target_date_value
            ).select_related()
            
            # æ‰¹é‡å¤„ç†ç»“æœ
            total_records = latest_records_qs.count()
            log_func(f"å…±æ‰¾åˆ° {total_records} æ¡æœ€æ–°è®°å½•éœ€è¦å¤„ç†")
            
            # åˆ†æ‰¹å¤„ç†ä»¥å‡å°‘å†…å­˜å ç”¨
            for i in range(0, total_records, batch_size):
                batch = latest_records_qs[i:i+batch_size]
                
                # ä½¿ç”¨å•ä¸ªäº‹åŠ¡å¤„ç†æ•´ä¸ªæ‰¹æ¬¡
                with transaction.atomic():
                    # å‡†å¤‡æ‰¹é‡æ“ä½œæ•°æ®
                    daily_records_to_update = []
                    daily_records_to_create = []
                    next_day_records_to_create = []
                    next_day_records_to_update = []
                    
                    # è·å–å½“å‰æ‰¹æ¬¡ä¸­æ‰€æœ‰specific_partå’Œenergy_modeçš„ç»„åˆ
                    batch_keys = [(record.specific_part, record.energy_mode) for record in batch]
                    
                    # æ‰¹é‡é¢„å–ç°æœ‰è®°å½•ä»¥å‡å°‘æ•°æ®åº“æŸ¥è¯¢
                    # é¢„å–ç›®æ ‡æ—¥æœŸçš„ç°æœ‰è®°å½•
                    current_day_existing_records = UsageQuantityDaily.objects.filter(
                        time_period=target_date_value,
                        specific_part__in=[key[0] for key in batch_keys],
                        energy_mode__in=[key[1] for key in batch_keys]
                    )
                    
                    # åˆ›å»ºç°æœ‰è®°å½•çš„æ˜ å°„ï¼Œç”¨äºO(1)æŸ¥æ‰¾
                    current_day_records_map = {(record.specific_part, record.energy_mode): record for record in current_day_existing_records}
                    
                    # é¢„å–æ¬¡æ—¥çš„ç°æœ‰è®°å½•
                    next_day_existing_records = UsageQuantityDaily.objects.filter(
                        time_period=next_day,
                        specific_part__in=[key[0] for key in batch_keys],
                        energy_mode__in=[key[1] for key in batch_keys]
                    )
                    
                    # åˆ›å»ºæ¬¡æ—¥ç°æœ‰è®°å½•çš„æ˜ å°„
                    next_day_records_map = {(record.specific_part, record.energy_mode): record for record in next_day_existing_records}
                    
                    for latest_record in batch:
                        specific_part = latest_record.specific_part
                        energy_mode = latest_record.energy_mode
                        final_energy = latest_record.value
                        
                        log_func(f"å¤„ç†: specific_part={specific_part}, energy_mode={energy_mode}, å€¼={final_energy}")
                        
                        # ä½¿ç”¨ç¼“å­˜çš„è§£æç»“æœ
                        if specific_part not in cls._specific_part_cache:
                            cls._specific_part_cache[specific_part] = cls.parse_specific_part(specific_part)
                        building, unit, room_number = cls._specific_part_cache[specific_part]
                        
                        # ä½¿ç”¨ä¸­æ–‡èƒ½æºæ¨¡å¼åç§°
                        mode_display = energy_mode
                        
                        # æŸ¥æ‰¾æ˜¯å¦å·²æœ‰å½“æ—¥è®°å½•
                        key = (specific_part, mode_display)
                        if key in current_day_records_map:
                            # æ›´æ–°ç°æœ‰è®°å½•
                            daily_record = current_day_records_map[key]
                            daily_record.final_energy = final_energy
                            daily_record.usage_quantity = final_energy - daily_record.initial_energy
                            daily_records_to_update.append(daily_record)
                            updated_count += 1
                        else:
                            # åˆ›å»ºæ–°è®°å½•
                            daily_records_to_create.append(UsageQuantityDaily(
                                time_period=target_date_value,
                                specific_part=specific_part,
                                energy_mode=mode_display,
                                building=building,
                                unit=unit,
                                room_number=room_number,
                                initial_energy=final_energy,
                                final_energy=final_energy,
                                usage_quantity=0
                            ))
                            created_count += 1
                        
                        # å¤„ç†æ¬¡æ—¥è®°å½•
                        if key in next_day_records_map:
                            # æ›´æ–°ç°æœ‰è®°å½•
                            next_record = next_day_records_map[key]
                            if not next_record.initial_energy:
                                next_record.initial_energy = final_energy
                                next_record.final_energy = None
                                next_record.usage_quantity = None
                                next_day_records_to_update.append(next_record)
                                next_day_count += 1
                        else:
                            # åˆ›å»ºæ¬¡æ—¥æ–°è®°å½•
                            next_day_records_to_create.append(UsageQuantityDaily(
                                time_period=next_day,
                                specific_part=specific_part,
                                energy_mode=mode_display,
                                building=building,
                                unit=unit,
                                room_number=room_number,
                                initial_energy=final_energy,
                                final_energy=None,
                                usage_quantity=None
                            ))
                            next_day_count += 1
                        
                        processed_count += 1
                    
                    # æ‰¹é‡ä¿å­˜è®°å½•ï¼ˆä½¿ç”¨bulk_createå’Œbulk_updateæé«˜æ€§èƒ½ï¼‰
                    if daily_records_to_create:
                        UsageQuantityDaily.objects.bulk_create(daily_records_to_create)
                    if daily_records_to_update:
                        UsageQuantityDaily.objects.bulk_update(
                            daily_records_to_update,
                            ['final_energy', 'usage_quantity']
                        )
                    if next_day_records_to_create:
                        UsageQuantityDaily.objects.bulk_create(next_day_records_to_create)
                    if next_day_records_to_update:
                        UsageQuantityDaily.objects.bulk_update(
                            next_day_records_to_update,
                            ['initial_energy', 'final_energy', 'usage_quantity']
                        )
            
            # è¿”å›å¤„ç†ç»“æœ
            result = {
                'processed_count': processed_count,
                'created_count': created_count,
                'updated_count': updated_count,
                'next_day_count': next_day_count
            }
            
            # è¾“å‡ºå¤„ç†ç»“æœ
            log_func(f"ğŸ“‹ å¤„ç†å®Œæˆ:")
            log_func(f"  âœ… æ€»å…±å¤„ç† {processed_count} æ¡ç‰¹å®šéƒ¨åˆ†è®°å½•")
            log_func(f"  âœ… æ–°å¢å½“æ—¥è®°å½• {created_count} æ¡")
            log_func(f"  âœ… æ›´æ–°å½“æ—¥è®°å½• {updated_count} æ¡")
            log_func(f"  âœ… åˆ›å»ºæ¬¡æ—¥è®°å½• {next_day_count} æ¡")
            log_func("âœ… è®¡ç®—å®Œæˆ")
            
            return result
            
        except Exception as e:
            error_msg = f"âŒ è®¡ç®—è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            log_func(error_msg)
            logger.error(error_msg, exc_info=True)
            raise
    
    @classmethod
    def get_db_index_recommendations(cls):
        """
        è·å–æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–å»ºè®®
        
        Returns:
            list: ç´¢å¼•åˆ›å»ºSQLè¯­å¥åˆ—è¡¨
        """
        return [
            # PLCDataè¡¨ç´¢å¼•ä¼˜åŒ–
            "CREATE INDEX idx_plcdata_usage_date ON api_plcdata(usage_date);",
            "CREATE INDEX idx_plcdata_specific_part ON api_plcdata(specific_part);",
            "CREATE INDEX idx_plcdata_energy_mode ON api_plcdata(energy_mode);",
            "CREATE INDEX idx_plcdata_updated_at ON api_plcdata(updated_at);",
            "CREATE INDEX idx_plcdata_combined ON api_plcdata(usage_date, specific_part, energy_mode);",
            "CREATE INDEX idx_plcdata_combined_latest ON api_plcdata(usage_date, specific_part, energy_mode, updated_at);",
            
            # UsageQuantityDailyè¡¨ç´¢å¼•ä¼˜åŒ–
            "CREATE INDEX idx_usagequantitydaily_time_period ON api_usagequantitydaily(time_period);",
            "CREATE INDEX idx_usagequantitydaily_specific_part ON api_usagequantitydaily(specific_part);",
            "CREATE INDEX idx_usagequantitydaily_energy_mode ON api_usagequantitydaily(energy_mode);",
            "CREATE INDEX idx_usagequantitydaily_combined ON api_usagequantitydaily(time_period, specific_part, energy_mode);"
        ]
    
    @staticmethod
    def parse_specific_part(specific_part):
        """
        è§£æspecific_partè·å–buildingã€unitã€room_number
        å‡è®¾æ ¼å¼ä¸º"building-unit-room_number"æˆ–ç›´æ¥æ˜¯æˆ¿é—´æ ‡è¯†ç¬¦
        """
        # é»˜è®¤å€¼
        building = ""
        unit = ""
        room_number = ""
        
        try:
            # å°è¯•è§£ææ ¼å¼"building-unit-room_number"
            parts = specific_part.split('-')
            if len(parts) == 3:
                building, unit, room_number = parts
            elif len(parts) == 4:
                # å¦‚æœæ˜¯æ ¼å¼å¦‚"3-1-7-702" (æ¥¼æ ‹-å•å…ƒ-æ¥¼å±‚-æˆ¿å·)
                building = parts[0]
                unit = parts[1]
                room_number = parts[3]  # ç¬¬4éƒ¨åˆ†æ˜¯æˆ¿å·
            else:
                # å¦‚æœæ— æ³•è§£æï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼Œspecific_partä½œä¸ºroom_number
                room_number = specific_part
        except Exception:
            # è§£æå¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤å€¼
            room_number = specific_part
        
        return building, unit, room_number